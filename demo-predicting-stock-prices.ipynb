{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Demo - Predicting Stock Prices with LSTM",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stevenseb/stock-predictor-google-colab/blob/main/demo-predicting-stock-prices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu9t476KSFbt"
      },
      "source": [
        "# Predicting Stock Prices with Deep Neural Networks\n",
        "\n",
        "This project walks you through the end-to-end data science lifecycle of developing a predictive model for stock price movements with Alpha Vantage APIs and a powerful machine learning algorithm called Long Short-Term Memory (LSTM). By completing this project, you will learn the key concepts of machine learning / deep learning and build a fully functional predictive model for the stock market, all in a single Python file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z68p_q4eISQP",
        "outputId": "346197b3-a470-467e-82ce-2fe0bc53b485"
      },
      "source": [
        "#@title Load Python libraries\n",
        "\n",
        "! pip install alpha_vantage -q\n",
        "\n",
        "# pip install numpy\n",
        "import numpy as np\n",
        "\n",
        "# pip install torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# pip install matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "# pip install alpha_vantage\n",
        "from alpha_vantage.timeseries import TimeSeries\n",
        "\n",
        "print(\"All libraries loaded\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUcYIRwMIVPV"
      },
      "source": [
        "config = {\n",
        "    \"alpha_vantage\": {\n",
        "        \"key\": \"TDTK3GYF0W5X4IKU\", # Claim your free API key here: https://www.alphavantage.co/support/#api-key\n",
        "        \"symbol\": \"IBM\",\n",
        "        \"outputsize\": \"full\",\n",
        "        \"key_adjusted_close\": \"5. adjusted close\",\n",
        "    },\n",
        "    \"data\": {\n",
        "        \"window_size\": 20,\n",
        "        \"train_split_size\": 0.80,\n",
        "    },\n",
        "    \"plots\": {\n",
        "        \"show_plots\": True,\n",
        "        \"xticks_interval\": 90,\n",
        "        \"color_actual\": \"#001f3f\",\n",
        "        \"color_train\": \"#3D9970\",\n",
        "        \"color_val\": \"#0074D9\",\n",
        "        \"color_pred_train\": \"#3D9970\",\n",
        "        \"color_pred_val\": \"#0074D9\",\n",
        "        \"color_pred_test\": \"#FF4136\",\n",
        "    },\n",
        "    \"model\": {\n",
        "        \"input_size\": 1, # since we are only using 1 feature, close price\n",
        "        \"num_lstm_layers\": 2,\n",
        "        \"lstm_size\": 32,\n",
        "        \"dropout\": 0.2,\n",
        "    },\n",
        "    \"training\": {\n",
        "        \"device\": \"cpu\", # \"cuda\" or \"cpu\"\n",
        "        \"batch_size\": 64,\n",
        "        \"num_epoch\": 100,\n",
        "        \"learning_rate\": 0.01,\n",
        "        \"scheduler_step_size\": 40,\n",
        "    }\n",
        "}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olYwt1apSFb6"
      },
      "source": [
        "## Data preparation: acquiring financial market data from Alpha Vantage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "j7bWYyArIVRq",
        "outputId": "89ba61fc-3a31-4ebc-931e-345da7dbf8f2"
      },
      "source": [
        "def download_data(config, plot=False):\n",
        "    # get the data from alpha vantage\n",
        "\n",
        "    ts = TimeSeries(key=config[\"alpha_vantage\"][\"key\"])\n",
        "    data, meta_data = ts.get_daily_adjusted(config[\"alpha_vantage\"][\"symbol\"])\n",
        "\n",
        "    data_date = [date for date in data.keys()]\n",
        "    data_date.reverse()\n",
        "\n",
        "    data_close_price = [float(data[date][config[\"alpha_vantage\"][\"key_adjusted_close\"]]) for date in data.keys()]\n",
        "    data_close_price.reverse()\n",
        "    data_close_price = np.array(data_close_price)\n",
        "\n",
        "    num_data_points = len(data_date)\n",
        "    display_date_range = \"from \" + data_date[0] + \" to \" + data_date[num_data_points-1]\n",
        "    print(\"Number data points:\", num_data_points, display_date_range)\n",
        "\n",
        "    if plot:\n",
        "        fig = figure(figsize=(25, 5), dpi=80)\n",
        "        fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
        "        plt.plot(data_date, data_close_price, color=config[\"plots\"][\"color_actual\"])\n",
        "        xticks = [data_date[i] if ((i%config[\"plots\"][\"xticks_interval\"]==0 and (num_data_points-i) > config[\"plots\"][\"xticks_interval\"]) or i==num_data_points-1) else None for i in range(num_data_points)] # make x ticks nice\n",
        "        x = np.arange(0,len(xticks))\n",
        "        plt.xticks(x, xticks, rotation='vertical')\n",
        "        plt.title(\"Daily close price for \" + config[\"alpha_vantage\"][\"symbol\"] + \", \" + display_date_range)\n",
        "        plt.grid(b=None, which='major', axis='y', linestyle='--')\n",
        "        plt.show()\n",
        "\n",
        "    return data_date, data_close_price, num_data_points, display_date_range\n",
        "\n",
        "data_date, data_close_price, num_data_points, display_date_range = download_data(config, plot=config[\"plots\"][\"show_plots\"])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-7f61107c4527>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_close_price\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_data_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_date_range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mdata_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_close_price\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_data_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_date_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"plots\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"show_plots\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-7f61107c4527>\u001b[0m in \u001b[0;36mdownload_data\u001b[0;34m(config, plot)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alpha_vantage\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"key\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_daily_adjusted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alpha_vantage\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"symbol\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alpha_vantage\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"outputsize\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdata_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdate\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/alpha_vantage/alphavantage.py\u001b[0m in \u001b[0;36m_format_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_format_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             call_response, data_key, meta_data_key = func(\n\u001b[0m\u001b[1;32m    219\u001b[0m                 self, *args, **kwargs)\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'json'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'pandas'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/alpha_vantage/alphavantage.py\u001b[0m in \u001b[0;36m_call_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapikey_parameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_data_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_call_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/alpha_vantage/alphavantage.py\u001b[0m in \u001b[0;36m_handle_api_call\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    359\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_response\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Error Message\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m\"Information\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_response\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtreat_info_as_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_response\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Information\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m\"Note\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_response\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtreat_info_as_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_response\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Note\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Thank you for using Alpha Vantage! This is a premium endpoint. You may subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly unlock all premium endpoints"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H3a86TCSFb8"
      },
      "source": [
        "## Data preparation: normalizing raw financial data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHo7IsI9ZknK"
      },
      "source": [
        "class Normalizer():\n",
        "    def __init__(self):\n",
        "        self.mu = None\n",
        "        self.sd = None\n",
        "\n",
        "    def fit_transform(self, x):\n",
        "        self.mu = np.mean(x, axis=(0), keepdims=True)\n",
        "        self.sd = np.std(x, axis=(0), keepdims=True)\n",
        "        normalized_x = (x - self.mu)/self.sd\n",
        "        return normalized_x\n",
        "\n",
        "    def inverse_transform(self, x):\n",
        "        return (x*self.sd) + self.mu\n",
        "\n",
        "# normalize\n",
        "scaler = Normalizer()\n",
        "normalized_data_close_price = scaler.fit_transform(data_close_price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mstDxZxSFb9"
      },
      "source": [
        "## Data preparation: generating training and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cinhNa4JRHu"
      },
      "source": [
        "def prepare_data_x(x, window_size):\n",
        "    # perform windowing\n",
        "    n_row = x.shape[0] - window_size + 1\n",
        "    output = np.lib.stride_tricks.as_strided(x, shape=(n_row,window_size), strides=(x.strides[0],x.strides[0]))\n",
        "    return output[:-1], output[-1]\n",
        "\n",
        "def prepare_data_y(x, window_size):\n",
        "    # # perform simple moving average\n",
        "    # output = np.convolve(x, np.ones(window_size), 'valid') / window_size\n",
        "\n",
        "    # use the next day as label\n",
        "    output = x[window_size:]\n",
        "    return output\n",
        "\n",
        "def prepare_data(normalized_data_close_price, config, plot=False):\n",
        "    data_x, data_x_unseen = prepare_data_x(normalized_data_close_price, window_size=config[\"data\"][\"window_size\"])\n",
        "    data_y = prepare_data_y(normalized_data_close_price, window_size=config[\"data\"][\"window_size\"])\n",
        "\n",
        "    # split dataset\n",
        "\n",
        "    split_index = int(data_y.shape[0]*config[\"data\"][\"train_split_size\"])\n",
        "    data_x_train = data_x[:split_index]\n",
        "    data_x_val = data_x[split_index:]\n",
        "    data_y_train = data_y[:split_index]\n",
        "    data_y_val = data_y[split_index:]\n",
        "\n",
        "    if plot:\n",
        "        # prepare data for plotting\n",
        "\n",
        "        to_plot_data_y_train = np.zeros(num_data_points)\n",
        "        to_plot_data_y_val = np.zeros(num_data_points)\n",
        "\n",
        "        to_plot_data_y_train[config[\"data\"][\"window_size\"]:split_index+config[\"data\"][\"window_size\"]] = scaler.inverse_transform(data_y_train)\n",
        "        to_plot_data_y_val[split_index+config[\"data\"][\"window_size\"]:] = scaler.inverse_transform(data_y_val)\n",
        "\n",
        "        to_plot_data_y_train = np.where(to_plot_data_y_train == 0, None, to_plot_data_y_train)\n",
        "        to_plot_data_y_val = np.where(to_plot_data_y_val == 0, None, to_plot_data_y_val)\n",
        "\n",
        "        ## plots\n",
        "\n",
        "        fig = figure(figsize=(25, 5), dpi=80)\n",
        "        fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
        "        plt.plot(data_date, to_plot_data_y_train, label=\"Prices (train)\", color=config[\"plots\"][\"color_train\"])\n",
        "        plt.plot(data_date, to_plot_data_y_val, label=\"Prices (validation)\", color=config[\"plots\"][\"color_val\"])\n",
        "        xticks = [data_date[i] if ((i%config[\"plots\"][\"xticks_interval\"]==0 and (num_data_points-i) > config[\"plots\"][\"xticks_interval\"]) or i==num_data_points-1) else None for i in range(num_data_points)] # make x ticks nice\n",
        "        x = np.arange(0,len(xticks))\n",
        "        plt.xticks(x, xticks, rotation='vertical')\n",
        "        plt.title(\"Daily close prices for \" + config[\"alpha_vantage\"][\"symbol\"] + \" - showing training and validation data\")\n",
        "        plt.grid(b=None, which='major', axis='y', linestyle='--')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    return split_index, data_x_train, data_y_train, data_x_val, data_y_val, data_x_unseen\n",
        "\n",
        "split_index, data_x_train, data_y_train, data_x_val, data_y_val, data_x_unseen = prepare_data(normalized_data_close_price, config, plot=config[\"plots\"][\"show_plots\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "begE6wtnJRL9"
      },
      "source": [
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        x = np.expand_dims(x, 2) # in our case, we have only 1 feature, so we need to convert `x` into [batch, sequence, features] for LSTM\n",
        "        self.x = x.astype(np.float32)\n",
        "        self.y = y.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.x[idx], self.y[idx])\n",
        "\n",
        "dataset_train = TimeSeriesDataset(data_x_train, data_y_train)\n",
        "dataset_val = TimeSeriesDataset(data_x_val, data_y_val)\n",
        "\n",
        "print(\"Train data shape\", dataset_train.x.shape, dataset_train.y.shape)\n",
        "print(\"Validation data shape\", dataset_val.x.shape, dataset_val.y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW8JIIAzSFcA"
      },
      "source": [
        "## Defining the LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ynCp-tnJROi"
      },
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_layer_size=32, num_layers=2, output_size=1, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.hidden_layer_size = hidden_layer_size\n",
        "\n",
        "        self.linear_1 = nn.Linear(input_size, hidden_layer_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lstm = nn.LSTM(hidden_layer_size, hidden_size=self.hidden_layer_size, num_layers=num_layers, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_2 = nn.Linear(num_layers*hidden_layer_size, output_size)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for name, param in self.lstm.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                 nn.init.constant_(param, 0.0)\n",
        "            elif 'weight_ih' in name:\n",
        "                 nn.init.kaiming_normal_(param)\n",
        "            elif 'weight_hh' in name:\n",
        "                 nn.init.orthogonal_(param)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.shape[0]\n",
        "\n",
        "        # layer 1\n",
        "        x = self.linear_1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # LSTM layer\n",
        "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "\n",
        "        # reshape output from hidden cell into [batch, features] for `linear_2`\n",
        "        x = h_n.permute(1, 0, 2).reshape(batchsize, -1)\n",
        "\n",
        "        # layer 2\n",
        "        x = self.dropout(x)\n",
        "        predictions = self.linear_2(x)\n",
        "        return predictions[:,-1]\n",
        "\n",
        "model = LSTMModel(input_size=config[\"model\"][\"input_size\"], hidden_layer_size=config[\"model\"][\"lstm_size\"], num_layers=config[\"model\"][\"num_lstm_layers\"], output_size=1, dropout=config[\"model\"][\"dropout\"])\n",
        "model = model.to(config[\"training\"][\"device\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66Rtd-wjSFcB"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv-3a2LZJhN9"
      },
      "source": [
        "def run_epoch(dataloader, is_training=False):\n",
        "    epoch_loss = 0\n",
        "\n",
        "    if is_training:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    for idx, (x, y) in enumerate(dataloader):\n",
        "        if is_training:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        batchsize = x.shape[0]\n",
        "\n",
        "        x = x.to(config[\"training\"][\"device\"])\n",
        "        y = y.to(config[\"training\"][\"device\"])\n",
        "\n",
        "        out = model(x)\n",
        "        loss = criterion(out.contiguous(), y.contiguous())\n",
        "\n",
        "        if is_training:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        epoch_loss += (loss.detach().item() / batchsize)\n",
        "\n",
        "    lr = scheduler.get_last_lr()[0]\n",
        "\n",
        "    return epoch_loss, lr\n",
        "\n",
        "# create `DataLoader`\n",
        "train_dataloader = DataLoader(dataset_train, batch_size=config[\"training\"][\"batch_size\"], shuffle=True)\n",
        "val_dataloader = DataLoader(dataset_val, batch_size=config[\"training\"][\"batch_size\"], shuffle=True)\n",
        "\n",
        "# define optimizer, scheduler and loss function\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=config[\"training\"][\"learning_rate\"], betas=(0.9, 0.98), eps=1e-9)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=config[\"training\"][\"scheduler_step_size\"], gamma=0.1)\n",
        "\n",
        "# begin training\n",
        "for epoch in range(config[\"training\"][\"num_epoch\"]):\n",
        "    loss_train, lr_train = run_epoch(train_dataloader, is_training=True)\n",
        "    loss_val, lr_val = run_epoch(val_dataloader)\n",
        "    scheduler.step()\n",
        "\n",
        "    print('Epoch[{}/{}] | loss train:{:.6f}, test:{:.6f} | lr:{:.6f}'\n",
        "              .format(epoch+1, config[\"training\"][\"num_epoch\"], loss_train, loss_val, lr_train))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQoZ0uHGSFcD"
      },
      "source": [
        "## Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCzupxOyJhQh"
      },
      "source": [
        "# here we re-initialize dataloader so the data doesn't shuffled, so we can plot the values by date\n",
        "\n",
        "train_dataloader = DataLoader(dataset_train, batch_size=config[\"training\"][\"batch_size\"], shuffle=False)\n",
        "val_dataloader = DataLoader(dataset_val, batch_size=config[\"training\"][\"batch_size\"], shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# predict on the training data, to see how well the model managed to learn and memorize\n",
        "\n",
        "predicted_train = np.array([])\n",
        "\n",
        "for idx, (x, y) in enumerate(train_dataloader):\n",
        "    x = x.to(config[\"training\"][\"device\"])\n",
        "    out = model(x)\n",
        "    out = out.cpu().detach().numpy()\n",
        "    predicted_train = np.concatenate((predicted_train, out))\n",
        "\n",
        "# predict on the validation data, to see how the model does\n",
        "\n",
        "predicted_val = np.array([])\n",
        "\n",
        "for idx, (x, y) in enumerate(val_dataloader):\n",
        "    x = x.to(config[\"training\"][\"device\"])\n",
        "    out = model(x)\n",
        "    out = out.cpu().detach().numpy()\n",
        "    predicted_val = np.concatenate((predicted_val, out))\n",
        "\n",
        "if config[\"plots\"][\"show_plots\"]:\n",
        "\n",
        "    # prepare data for plotting, show predicted prices\n",
        "\n",
        "    to_plot_data_y_train_pred = np.zeros(num_data_points)\n",
        "    to_plot_data_y_val_pred = np.zeros(num_data_points)\n",
        "\n",
        "    to_plot_data_y_train_pred[config[\"data\"][\"window_size\"]:split_index+config[\"data\"][\"window_size\"]] = scaler.inverse_transform(predicted_train)\n",
        "    to_plot_data_y_val_pred[split_index+config[\"data\"][\"window_size\"]:] = scaler.inverse_transform(predicted_val)\n",
        "\n",
        "    to_plot_data_y_train_pred = np.where(to_plot_data_y_train_pred == 0, None, to_plot_data_y_train_pred)\n",
        "    to_plot_data_y_val_pred = np.where(to_plot_data_y_val_pred == 0, None, to_plot_data_y_val_pred)\n",
        "\n",
        "    # plots\n",
        "\n",
        "    fig = figure(figsize=(25, 5), dpi=80)\n",
        "    fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
        "    plt.plot(data_date, data_close_price, label=\"Actual prices\", color=config[\"plots\"][\"color_actual\"])\n",
        "    plt.plot(data_date, to_plot_data_y_train_pred, label=\"Predicted prices (train)\", color=config[\"plots\"][\"color_pred_train\"])\n",
        "    plt.plot(data_date, to_plot_data_y_val_pred, label=\"Predicted prices (validation)\", color=config[\"plots\"][\"color_pred_val\"])\n",
        "    plt.title(\"Compare predicted prices to actual prices\")\n",
        "    xticks = [data_date[i] if ((i%config[\"plots\"][\"xticks_interval\"]==0 and (num_data_points-i) > config[\"plots\"][\"xticks_interval\"]) or i==num_data_points-1) else None for i in range(num_data_points)] # make x ticks nice\n",
        "    x = np.arange(0,len(xticks))\n",
        "    plt.xticks(x, xticks, rotation='vertical')\n",
        "    plt.grid(b=None, which='major', axis='y', linestyle='--')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # prepare data for plotting, zoom in validation\n",
        "\n",
        "    to_plot_data_y_val_subset = scaler.inverse_transform(data_y_val)\n",
        "    to_plot_predicted_val = scaler.inverse_transform(predicted_val)\n",
        "    to_plot_data_date = data_date[split_index+config[\"data\"][\"window_size\"]:]\n",
        "\n",
        "    # plots\n",
        "\n",
        "    fig = figure(figsize=(25, 5), dpi=80)\n",
        "    fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
        "    plt.plot(to_plot_data_date, to_plot_data_y_val_subset, label=\"Actual prices\", color=config[\"plots\"][\"color_actual\"])\n",
        "    plt.plot(to_plot_data_date, to_plot_predicted_val, label=\"Predicted prices (validation)\", color=config[\"plots\"][\"color_pred_val\"])\n",
        "    plt.title(\"Zoom in to examine predicted price on validation data portion\")\n",
        "    xticks = [to_plot_data_date[i] if ((i%int(config[\"plots\"][\"xticks_interval\"]/5)==0 and (len(to_plot_data_date)-i) > config[\"plots\"][\"xticks_interval\"]/6) or i==len(to_plot_data_date)-1) else None for i in range(len(to_plot_data_date))] # make x ticks nice\n",
        "    xs = np.arange(0,len(xticks))\n",
        "    plt.xticks(xs, xticks, rotation='vertical')\n",
        "    plt.grid(b=None, which='major', axis='y', linestyle='--')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-X8WO0FSFcE"
      },
      "source": [
        "## Predicting future stock prices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgSOzYuXJrdU"
      },
      "source": [
        "# predict on the unseen data, tomorrow's price\n",
        "\n",
        "model.eval()\n",
        "\n",
        "x = torch.tensor(data_x_unseen).float().to(config[\"training\"][\"device\"]).unsqueeze(0).unsqueeze(2) # this is the data type and shape required, [batch, sequence, feature]\n",
        "prediction = model(x)\n",
        "prediction = prediction.cpu().detach().numpy()\n",
        "prediction = scaler.inverse_transform(prediction)[0]\n",
        "\n",
        "if config[\"plots\"][\"show_plots\"]:\n",
        "\n",
        "    # prepare plots\n",
        "\n",
        "    plot_range = 10\n",
        "    to_plot_data_y_val = np.zeros(plot_range)\n",
        "    to_plot_data_y_val_pred = np.zeros(plot_range)\n",
        "    to_plot_data_y_test_pred = np.zeros(plot_range)\n",
        "\n",
        "    to_plot_data_y_val[:plot_range-1] = scaler.inverse_transform(data_y_val)[-plot_range+1:]\n",
        "    to_plot_data_y_val_pred[:plot_range-1] = scaler.inverse_transform(predicted_val)[-plot_range+1:]\n",
        "\n",
        "    to_plot_data_y_test_pred[plot_range-1] = prediction\n",
        "\n",
        "    to_plot_data_y_val = np.where(to_plot_data_y_val == 0, None, to_plot_data_y_val)\n",
        "    to_plot_data_y_val_pred = np.where(to_plot_data_y_val_pred == 0, None, to_plot_data_y_val_pred)\n",
        "    to_plot_data_y_test_pred = np.where(to_plot_data_y_test_pred == 0, None, to_plot_data_y_test_pred)\n",
        "\n",
        "    # plot\n",
        "\n",
        "    plot_date_test = data_date[-plot_range+1:]\n",
        "    plot_date_test.append(\"next trading day\")\n",
        "\n",
        "    fig = figure(figsize=(25, 5), dpi=80)\n",
        "    fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
        "    plt.plot(plot_date_test, to_plot_data_y_val, label=\"Actual prices\", marker=\".\", markersize=10, color=config[\"plots\"][\"color_actual\"])\n",
        "    plt.plot(plot_date_test, to_plot_data_y_val_pred, label=\"Past predicted prices\", marker=\".\", markersize=10, color=config[\"plots\"][\"color_pred_val\"])\n",
        "    plt.plot(plot_date_test, to_plot_data_y_test_pred, label=\"Predicted price for next day\", marker=\".\", markersize=20, color=config[\"plots\"][\"color_pred_test\"])\n",
        "    plt.title(\"Predicted close price of the next trading day\")\n",
        "    plt.grid(b=None, which='major', axis='y', linestyle='--')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "print(\"Predicted close price of the next trading day:\", round(prediction, 2))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}